{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data_generation_for_plotting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "96cEPRvwQYm-"
      },
      "source": [
        "!git clone -b 'new_truncation_scheme' 'https://github.com/LuchnikovI/Dynamic-mode-decomposition-for-open-quantum-systems-identification'\n",
        "%cd 'Dynamic-mode-decomposition-for-open-quantum-systems-identification'\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nmd_finite_env import FiniteEnv\n",
        "from embedding import Embedding\n",
        "from utils import optimal_K\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsEYrMbryUBe"
      },
      "source": [
        "## Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aohkyhOlnXz2"
      },
      "source": [
        "# Pauli matrices\n",
        "sigma_x = tf.constant([[0, 1], [1, 0]], dtype=tf.complex128)\n",
        "sigma_y = 1j * tf.constant([[0, -1], [1, 0]], dtype=tf.complex128)\n",
        "sigma_z = tf.constant([[1, 0], [0, -1]], dtype=tf.complex128)\n",
        "\n",
        "# all Pauli matrices in one tensor\n",
        "pauli = tf.concat([sigma_x[tf.newaxis],\n",
        "                   sigma_y[tf.newaxis],\n",
        "                   sigma_z[tf.newaxis]], axis=0)\n",
        "\n",
        "\n",
        "def data_generation_and_fit(model, rho, eps,\n",
        "                            total_time=20, time_step=0.3,\n",
        "                            K=25, auto_K=False):\n",
        "    '''The function performs the generation of data\n",
        "    with given parameters and fits them by using DMD.\n",
        "\n",
        "    Args:\n",
        "        model: model of non-Markovian dynamics\n",
        "        rho: complex valued tensor of shape (number_of_lines, 2, 2), initial\n",
        "            density matrices\n",
        "        eps: real valued number, std of additive noise\n",
        "        total_time: real valued number, total time\n",
        "        time_step: real valued number, time step\n",
        "        K: integer number, memory depth\n",
        "        auto_K: boolean number showing if one needs to\n",
        "            use automatic K determination\n",
        "\n",
        "    Returns: dict with data, includes the following keys:\n",
        "        'rank' is the dimension of the Markovian embedding,\n",
        "        'K' is the memory depth,\n",
        "        'X_test' is a test sample of dynamics in terms of Bloch vectors\n",
        "        'X_predicted' is the prediction of test dynamics\n",
        "        'X_test_noisy' is the noisy version of 'X_test'\n",
        "        'true_phi_lmbd' is eigenvalues of the quantum channel\n",
        "        'learned_phi_lmbd' is eigenvalues of the embedding\n",
        "        'denoised_X' is a denoised trajectory from data set\n",
        "        'noisy_X' is a noisy trajectory from data set\n",
        "        'noiseless_X' is a noiseless trajectory from data set\n",
        "        '''\n",
        "\n",
        "    # training set without noise\n",
        "    train_set_wo_noise = model.dynamics(total_time, time_step, rho)\n",
        "    # noise\n",
        "    noise = tf.complex(tf.random.normal(train_set_wo_noise.shape, dtype=tf.float64),\n",
        "                       tf.random.normal(train_set_wo_noise.shape, dtype=tf.float64))\n",
        "    # training set with noise\n",
        "    train_set = train_set_wo_noise + eps * tf.complex(tf.random.normal(train_set_wo_noise.shape, dtype=tf.float64),\n",
        "                                                      tf.random.normal(train_set_wo_noise.shape, dtype=tf.float64))\n",
        "\n",
        "    # embedding\n",
        "    emb = Embedding()\n",
        "\n",
        "    # learn embedding\n",
        "    if auto_K:\n",
        "        denoised_t = emb.learn(train_set, eps=eps, auto_K=True, denoise=True)\n",
        "    else:\n",
        "        denoised_t = emb.learn(train_set, K=K, eps=eps, denoise=True)\n",
        "    \n",
        "    # sample of noisy, noiseless and denoised trajectories from data set\n",
        "    denoised_X = tf.tensordot(denoised_t[0], pauli, [[1, 2], [2, 1]])\n",
        "    noisy_X = tf.tensordot(train_set[0], pauli, [[1, 2], [2, 1]])\n",
        "    noiseless_X = tf.tensordot(train_set_wo_noise[0], pauli, [[1, 2], [2, 1]])\n",
        "    \n",
        "    # embedding dim\n",
        "    rank = emb.rank\n",
        "    # memory depth\n",
        "    K = emb.K\n",
        "\n",
        "    # test set\n",
        "    rho_test = tf.constant([[1, 0], [0, 0]], dtype=tf.complex128)[tf.newaxis]\n",
        "    test_set = model.dynamics(total_time, time_step, rho_test)\n",
        "    # noisy test set\n",
        "    noise = tf.complex(tf.random.normal(train_set_wo_noise.shape, dtype=tf.float64),\n",
        "                       tf.random.normal(train_set_wo_noise.shape, dtype=tf.float64))\n",
        "    test_set_noisy = test_set  + eps * noise\n",
        "    # prediction\n",
        "    prediction = emb.predict(test_set_noisy[0, :K],\n",
        "                             test_set_noisy.shape[1]-K)\n",
        "\n",
        "    # predicted Bloch vectors\n",
        "    X_predicted = tf.tensordot(prediction, pauli, [[1, 2], [2, 1]])\n",
        "    # test Bloch vectors\n",
        "    X_test = tf.tensordot(test_set, pauli, [[2, 3], [2, 1]])\n",
        "    # noisy test bloch vectors\n",
        "    X_test_noisy = tf.tensordot(test_set_noisy, pauli, [[2, 3], [2, 1]])\n",
        "    #X_pred_input = tf.tensordot(test_set[:, :K], pauli, [[2, 3], [2, 1]])\n",
        "\n",
        "    # exact channel eigenvalues\n",
        "    true_gen_lmbd, _ = tf.linalg.eig(model.gen)\n",
        "    true_phi_lmbd = tf.math.exp(time_step * true_gen_lmbd)\n",
        "\n",
        "    # learned eigenvalues\n",
        "    learned_phi_lmbd = emb.channel\n",
        "\n",
        "    data = {}\n",
        "    data['rank'] = rank\n",
        "    data['K'] = K\n",
        "    data['X_test'] = X_test\n",
        "    data['X_predicted'] = X_predicted\n",
        "    data['X_test_noisy'] = X_test_noisy\n",
        "    data['true_phi_lmbd'] = true_phi_lmbd\n",
        "    data['learned_phi_lmbd'] = learned_phi_lmbd\n",
        "    data['denoised_X'] = denoised_X\n",
        "    data['noisy_X'] = noisy_X\n",
        "    data['noiseless_X'] = noiseless_X\n",
        "    return data\n",
        "\n",
        "def generation_experiments(list_of_mem_dims,\n",
        "                           list_of_eps,\n",
        "                           list_of_K,\n",
        "                           dissipation_ampl=0.1,\n",
        "                           hamiltonian_ampl=1,\n",
        "                           time_step=0.2,\n",
        "                           total_time=40,\n",
        "                           number_of_lines=4):\n",
        "    '''Returns data for plotting.\n",
        "\n",
        "    Args:\n",
        "        list_of_dims: list with values of environment dimension\n",
        "        list_of_eps: list with values of noise std\n",
        "        list_of_K: list with values of memory depth\n",
        "        dissipation_ampl: real valued number showing the amplitude\n",
        "            of the dissipator\n",
        "        hamiltonian_ampl: real valued number showing the amplitude\n",
        "            of the Hamiltonian part\n",
        "        time_step: real valued number, time step size\n",
        "        total_time: real valued number, total simmulation time\n",
        "        number_of_lines, integer number, number of trajectories\n",
        "\n",
        "    Returns:\n",
        "        nested dictionaries with data.'''\n",
        "\n",
        "    data_dict = {}  \n",
        "    for mem_dim in list_of_mem_dims:\n",
        "\n",
        "        #  model for data generation\n",
        "        model = FiniteEnv(2, mem_dim)\n",
        "        model.set_rand_gen(dissipation_ampl / ((2 * mem_dim) ** 2 - 1), hamiltonian_ampl)\n",
        "\n",
        "        # random pure initial states\n",
        "        psi_re = tf.random.normal((number_of_lines, 2), dtype=tf.float64)\n",
        "        psi_im = tf.random.normal((number_of_lines, 2), dtype=tf.float64)\n",
        "        psi = tf.complex(psi_re, psi_im)\n",
        "        psi = psi / tf.linalg.norm(psi, axis=1, keepdims=True)\n",
        "        rho = psi[:, tf.newaxis] * tf.math.conj(psi)[..., tf.newaxis]\n",
        "\n",
        "        #  main loop\n",
        "        eps_dict = {}\n",
        "        for eps in list_of_eps:\n",
        "            K_dict = {}\n",
        "            for K in list_of_K:\n",
        "                data = data_generation_and_fit(model,\n",
        "                                               rho,\n",
        "                                               eps,\n",
        "                                               total_time=total_time,\n",
        "                                               time_step=time_step,\n",
        "                                               K=K, auto_K=False)\n",
        "                K_dict[K] = data\n",
        "            eps_dict[eps] = K_dict\n",
        "        data_dict[mem_dim] = eps_dict\n",
        "    return data_dict"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lUGTsTKIR4l"
      },
      "source": [
        "## Data generation and saving"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5PU4dwBzSsy"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "list_of_mem_dims = [2, 3, 4, 5, 6]\n",
        "list_of_eps = [1e-10, 0.001, 0.003, 0.01, 0.03, 0.1]\n",
        "list_of_K = [5, 15, 30, 45, 60, 75]\n",
        "data = generation_experiments(list_of_mem_dims, list_of_eps, list_of_K)\n",
        "with open('data.pickle', 'wb') as f:\n",
        "    pickle.dump(data, f)"
      ],
      "execution_count": 11,
      "outputs": []
    }
  ]
}